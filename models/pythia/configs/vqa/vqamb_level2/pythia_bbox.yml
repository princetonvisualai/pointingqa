includes:
- common/defaults/configs/tasks/vqa/vqamb_level2bbox.yml
model_attributes:
  pythia_bbox: &pythia_bbox
    model_data_dir: ../data/
    metrics:
      # - vqamb_f1pt
      - type: accuracy
      # - type: vqamb_map
      # - type: vqamb_f1
    losses:
      - type: nll_loss
    #   - type: logit_bce
    #  - type: logit_bce_wt
    # - type: logit_bce
    classifier:
      type: logit
      params:
        img_hidden_dim: 5000
        text_hidden_dim: 300
    image_feature_embeddings:
    - modal_combine:
        type: non_linear_element_multiply_three
        params:
          dropout: 0
          hidden_dim: 5000
      normalization: softmax
      transform:
        type: linear
        params:
          out_dim: 1
    image_feature_dim: 2048
    image_feature_encodings:
    - type: finetune_faster_rcnn_fpn_fc7
      params:
        bias_file: detectron/detectron/fc6/fc7_b.pkl
        weights_file: detectron/detectron/fc6/fc7_w.pkl
    context_feature_dim: 2048
    context_feature_encodings:
    - type: finetune_faster_rcnn_fpn_fc7
      params:
        bias_file: detectron/detectron/fc6/fc7_b.pkl
        weights_file: detectron/detectron/fc6/fc7_w.pkl
    # - type: default
    #  params: {}
    image_text_modal_combine:
      type: non_linear_element_multiply_three
      params:
        dropout: 0
        hidden_dim: 5000
    text_embeddings:
    - type: attention
      params:
        hidden_dim: 1024
        num_layers: 1
        conv1_out: 512
        conv2_out: 2
        dropout: 0
        embedding_dim: 300
        kernel_size: 1
        padding: 0
  # pythia_image_only: *pythia
  # pythia_question_only: *pythia
optimizer_attributes:
  type: Adamax
  params:
    eps: 1.0e-08
    lr: 0.002
    weight_decay: 0
training_parameters:
  # data_parallel: true # Creating errors right now
  clip_norm_mode: all
  clip_gradients: true
  #  lr_ratio: 0.1
  # lr_scheduler: true
  # lr_steps:
  # - 15000
  # - 18000
  # - 20000
  # - 21000
  max_grad_l2_norm: 0.25
  max_epochs: 100
  # use_warmup: true
  # warmup_factor: 0.2
  # warmup_iterations: 1000
  patience: 500 # number of iterations for early stopping
  batch_size: 128
  num_workers: 0
  log_interval: 20
  snapshot_interval: 20
  experiment_name: 'pythia_looktwice5_bbox'
  # early stopping options
  # monitored_metric: vqamb_f1
  monitored_metric: accuracy
  metric_minimize: False
  should_early_stop: True
  model_file: 'pythia_looktwice5_bbox'
  



